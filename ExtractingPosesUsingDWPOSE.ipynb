{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lrLqrZsG5CP",
        "outputId": "4a9cbae2-0cdb-4344-9dce-30354c325d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.86)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement onnxruntime==1.13.1 (from versions: 1.15.0, 1.15.1, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.17.0, 1.17.1, 1.17.3, 1.18.0, 1.18.1, 1.19.0, 1.19.2, 1.20.0, 1.20.1, 1.21.0, 1.21.1, 1.22.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for onnxruntime==1.13.1\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement onnxruntime-gpu==1.13.1 (from versions: 1.15.0, 1.15.1, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.17.0, 1.17.1, 1.18.0, 1.18.1, 1.19.0, 1.19.2, 1.20.0, 1.20.1, 1.20.2, 1.21.0, 1.21.1, 1.22.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for onnxruntime-gpu==1.13.1\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: matplotlib==3.6.2 in /usr/local/lib/python3.11/dist-packages (3.6.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.6.2) (1.17.0)\n",
            "Requirement already satisfied: opencv-python==4.7.0.68 in /usr/local/lib/python3.11/dist-packages (4.7.0.68)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python==4.7.0.68) (1.26.4)\n",
            "Requirement already satisfied: scipy==1.11.4 in /usr/local/lib/python3.11/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from scipy==1.11.4) (1.26.4)\n",
            "Collecting scikit-image==0.19.3\n",
            "  Using cached scikit-image-0.19.3.tar.gz (22.2 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (3.5)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (11.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (2025.6.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (1.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.19.3) (24.2)\n",
            "Building wheels for collected packages: scikit-image\n",
            "  Building wheel for scikit-image (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-image: filename=scikit_image-0.19.3-cp311-cp311-linux_x86_64.whl size=33913347 sha256=bb404ca34c1a65371620968758f5b7b6d57d80d8895c52075b65eea667fa4388\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/12/cd/f311cabf9e8708d1e29e9951ee0839fb89b69e1acc60c94927\n",
            "Successfully built scikit-image\n",
            "Installing collected packages: scikit-image\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.25.2\n",
            "    Uninstalling scikit-image-0.25.2:\n",
            "      Successfully uninstalled scikit-image-0.25.2\n",
            "Successfully installed scikit-image-0.19.3\n",
            "Collecting huggingface_hub==0.20.1\n",
            "  Using cached huggingface_hub-0.20.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.1) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.1) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.1) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.1) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.1) (4.14.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.1) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.1) (2025.4.26)\n",
            "Using cached huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\n",
            "Installing collected packages: huggingface_hub\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.33.0\n",
            "    Uninstalling huggingface-hub-0.33.0:\n",
            "      Successfully uninstalled huggingface-hub-0.33.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "accelerate 1.7.0 requires huggingface-hub>=0.21.0, but you have huggingface-hub 0.20.1 which is incompatible.\n",
            "gradio 5.31.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.20.1 which is incompatible.\n",
            "peft 0.15.2 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.20.1 which is incompatible.\n",
            "diffusers 0.33.1 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.20.1 which is incompatible.\n",
            "transformers 4.52.4 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 0.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface_hub-0.20.1\n",
            "Collecting dwpose\n",
            "  Downloading dwpose-1.0.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading dwpose-1.0.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dwpose\n",
            "Successfully installed dwpose-1.0.1\n"
          ]
        }
      ],
      "source": [
        "# Install core dependencies\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install ONNX and supporting libraries\n",
        "!pip install onnxruntime==1.13.1\n",
        "!pip install onnxruntime-gpu==1.13.1\n",
        "\n",
        "# Install utility libraries\n",
        "!pip install matplotlib==3.6.2\n",
        "!pip install opencv-python==4.7.0.68\n",
        "!pip install scipy==1.11.4\n",
        "!pip install scikit-image==0.19.3\n",
        "!pip install huggingface_hub==0.20.1\n",
        "\n",
        "# Install DWPose (ONNX-based version)\n",
        "!pip install dwpose\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime==1.17.1\n",
        "!pip install onnxruntime-gpu==1.17.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D0mSzzRH3BL",
        "outputId": "242dc3ae-65fd-4da2-9589-4466f512ea6f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime==1.17.1\n",
            "  Downloading onnxruntime-1.17.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting coloredlogs (from onnxruntime==1.17.1)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.17.1) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.17.1) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.17.1) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.17.1) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.17.1) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.17.1)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime==1.17.1) (1.3.0)\n",
            "Downloading onnxruntime-1.17.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.1\n",
            "Collecting onnxruntime-gpu==1.17.1\n",
            "  Downloading onnxruntime_gpu-1.17.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.17.1) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.17.1) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.17.1) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.17.1) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.17.1) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.17.1) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime-gpu==1.17.1) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu==1.17.1) (1.3.0)\n",
            "Downloading onnxruntime_gpu-1.17.1-cp311-cp311-manylinux_2_28_x86_64.whl (192.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.1/192.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnxruntime-gpu\n",
            "Successfully installed onnxruntime-gpu-1.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded file path\n",
        "image_path = next(iter(uploaded))\n",
        "print(\"Uploaded:\", image_path)\n",
        "\n",
        "from dwpose import DwposeDetector\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "\n",
        "# === Setup ===\n",
        "video_path = image_path\n",
        "output_json = \"normalized_pose.json\"\n",
        "\n",
        "# === Load DWPose model ===\n",
        "model = DwposeDetector.from_pretrained_default()\n",
        "\n",
        "# === Load and crop image ===\n",
        "img = Image.open(video_path).convert(\"RGB\")\n",
        "img_width, img_height = img.size\n",
        "left_img = img.crop((0, 0, img_width // 2, img_height))\n",
        "\n",
        "# === Step 1: Count people in full image ===\n",
        "_, keypoints_json_full, _ = model(\n",
        "    img,\n",
        "    include_hand=True,\n",
        "    include_face=True,\n",
        "    include_body=True,\n",
        "    image_and_json=True,\n",
        "    detect_resolution=512\n",
        ")\n",
        "\n",
        "num_people = len(keypoints_json_full.get('people', []))\n",
        "print(f\"Detected {num_people} person(s) in full image\")\n",
        "\n",
        "# === Step 2: Choose cropped input if needed ===\n",
        "selected_img = img if num_people <= 1 else left_img\n",
        "\n",
        "# === Step 3: Final inference ===\n",
        "imgOut, keypoints_json_all, source_img = model(\n",
        "    selected_img,\n",
        "    include_hand=True,\n",
        "    include_face=True,\n",
        "    include_body=True,\n",
        "    image_and_json=True,\n",
        "    detect_resolution=512\n",
        ")\n",
        "\n",
        "# === Step 4: Try to get person closest to center, fallback to first person ===\n",
        "def get_bbox_center(bbox):\n",
        "    x, y, w, h = bbox\n",
        "    return np.array([x + w / 2, y + h / 2])\n",
        "\n",
        "people = keypoints_json_all.get('people', [])\n",
        "if not people:\n",
        "    raise ValueError(\"No people detected in the selected image.\")\n",
        "\n",
        "image_center = np.array([img_width / 2, img_height / 2])\n",
        "min_dist = float('inf')\n",
        "best_person = None\n",
        "\n",
        "for person in people:\n",
        "    bbox = person.get('bbox')\n",
        "    if bbox is None:\n",
        "        continue\n",
        "    center = get_bbox_center(bbox)\n",
        "    dist = np.linalg.norm(center - image_center)\n",
        "    if dist < min_dist:\n",
        "        min_dist = dist\n",
        "        best_person = person\n",
        "\n",
        "# Fallback if no person with valid bbox\n",
        "if best_person is None:\n",
        "    print(\"No valid bbox found, falling back to first detected person.\")\n",
        "    best_person = people[0]\n",
        "\n",
        "# === Normalize pose ===\n",
        "pose_flat = best_person[\"pose_keypoints_2d\"]\n",
        "pose = np.array(pose_flat).reshape(-1, 3)   # (J, 3)\n",
        "pose_xy = pose[:, :2]\n",
        "\n",
        "# Center by hips\n",
        "hip_center = (pose_xy[11] + pose_xy[12]) / 2\n",
        "\n",
        "# Scale by shoulder span\n",
        "shoulder_span = np.linalg.norm(pose_xy[5] - pose_xy[6])\n",
        "if shoulder_span == 0:\n",
        "    raise ValueError(\"Shoulder span is zero — possibly missing keypoints.\")\n",
        "\n",
        "pose_normalized = (pose_xy - hip_center) / shoulder_span\n",
        "\n",
        "# Compute relative vectors\n",
        "edges = [\n",
        "    (5, 7), (7, 9),     # left arm\n",
        "    (6, 8), (8, 10),    # right arm\n",
        "    (11, 13), (13, 15), # left leg\n",
        "    (12, 14), (14, 16), # right leg\n",
        "    (5, 6), (11, 12),   # shoulders + hips\n",
        "    (5, 11), (6, 12)    # torso\n",
        "]\n",
        "rel_pose = [(pose_normalized[j] - pose_normalized[i]).tolist() for i, j in edges]\n",
        "\n",
        "# === Save JSON ===\n",
        "data = {\n",
        "    \"image\": os.path.basename(video_path),\n",
        "    \"pose_normalized\": pose_normalized.tolist(),\n",
        "    \"relative_pose_vectors\": rel_pose,\n",
        "    \"edges\": edges\n",
        "}\n",
        "\n",
        "with open(output_json, \"w\") as f:\n",
        "    json.dump(data, f, indent=2)\n",
        "\n",
        "# === Save visual output ===\n",
        "imgOut.save(\"openpose_output.jpg\")\n",
        "source_img.save(\"source_resized.jpg\")\n",
        "\n",
        "print(f\"✅ Saved normalized pose to {output_json}\")\n",
        "\n",
        "# === Show pose output ===\n",
        "from IPython.display import Image as IPyImage\n",
        "IPyImage(\"openpose_output.jpg\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "CuJHOCs8H9R7",
        "outputId": "68ff11a9-4d6e-4651-92a8-c620025088e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7416a6c6-9adc-4edc-9fa2-3c01a8ccece2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7416a6c6-9adc-4edc-9fa2-3c01a8ccece2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving clips_10s_video1_clip_000_frame_0000.jpg to clips_10s_video1_clip_000_frame_0000 (3).jpg\n",
            "Uploaded: clips_10s_video1_clip_000_frame_0000 (3).jpg\n",
            "\n",
            "DWPose: Using yolox_l.onnx for bbox detection and dw-ll_ucoco_384.onnx for pose estimation\n",
            "DWPose: Bbox 1534.85ms\n",
            "DWPose: Pose 266.50ms on 1 people\n",
            "\n",
            "Detected 1 person(s) in full image\n",
            "DWPose: Bbox 1480.68ms\n",
            "DWPose: Pose 227.77ms on 1 people\n",
            "\n",
            "No valid bbox found, falling back to first detected person.\n",
            "✅ Saved normalized pose to normalized_pose.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dwpose import DwposeDetector\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.cloud import storage\n",
        "\n",
        "# ==== CONFIG ====\n",
        "bucket_name = \"ucftoy-dataset\"\n",
        "gcs_input_root = \"clips_10s_video1\"\n",
        "gcs_output_root = \"pose_jsons\"\n",
        "local_root = \"/tmp/pose_processing\"\n",
        "\n",
        "# ==== INIT ====\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "model = DwposeDetector.from_pretrained_default()\n",
        "\n",
        "# ==== UTILS ====\n",
        "def get_bbox_center(bbox):\n",
        "    x, y, w, h = bbox\n",
        "    return np.array([x + w / 2, y + h / 2])\n",
        "\n",
        "def list_clip_folders():\n",
        "    blobs = storage_client.list_blobs(bucket_name, prefix=gcs_input_root + \"/\")\n",
        "    return sorted(set(b.name.split(\"/\")[1] for b in blobs if \"frame_\" in b.name))\n",
        "\n",
        "# ==== PROCESSING LOOP ====\n",
        "for clip_id in list_clip_folders():\n",
        "    gcs_clip_path = f\"{gcs_input_root}/{clip_id}\"\n",
        "    print(f\"\\nProcessing {gcs_clip_path}...\")\n",
        "\n",
        "    blobs = storage_client.list_blobs(bucket_name, prefix=gcs_clip_path)\n",
        "    frame_blobs = sorted([b for b in blobs if b.name.endswith(\".jpg\")], key=lambda b: b.name)\n",
        "\n",
        "    for blob in tqdm(frame_blobs, desc=f\"🎯 {clip_id}\"):\n",
        "        filename = os.path.basename(blob.name)\n",
        "        local_dir = os.path.join(local_root, clip_id)\n",
        "        os.makedirs(local_dir, exist_ok=True)\n",
        "\n",
        "        local_path = os.path.join(local_dir, filename)\n",
        "        blob.download_to_filename(local_path)\n",
        "\n",
        "        try:\n",
        "            img = Image.open(local_path).convert(\"RGB\")\n",
        "            img_width, img_height = img.size\n",
        "            left_img = img.crop((0, 0, img_width // 2, img_height))\n",
        "\n",
        "            # Step 1: count people in full image\n",
        "            _, keypoints_json_full, _ = model(\n",
        "                img,\n",
        "                include_hand=True,\n",
        "                include_face=True,\n",
        "                include_body=True,\n",
        "                image_and_json=True,\n",
        "                detect_resolution=512\n",
        "            )\n",
        "            num_people = len(keypoints_json_full.get(\"people\", []))\n",
        "            selected_img = img if num_people <= 1 else left_img\n",
        "\n",
        "            # Step 2: final pose estimation\n",
        "            _, keypoints_json, _ = model(\n",
        "                selected_img,\n",
        "                include_hand=True,\n",
        "                include_face=True,\n",
        "                include_body=True,\n",
        "                image_and_json=True,\n",
        "                detect_resolution=512\n",
        "            )\n",
        "\n",
        "            people = keypoints_json.get(\"people\", [])\n",
        "            if not people:\n",
        "                continue\n",
        "\n",
        "            # Step 3: pick person closest to center\n",
        "            image_center = np.array([selected_img.width / 2, selected_img.height / 2])\n",
        "            best_person = None\n",
        "            min_dist = float('inf')\n",
        "            for person in people:\n",
        "                bbox = person.get(\"bbox\")\n",
        "                if bbox is None:\n",
        "                    continue\n",
        "                center = get_bbox_center(bbox)\n",
        "                dist = np.linalg.norm(center - image_center)\n",
        "                if dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    best_person = person\n",
        "            if best_person is None:\n",
        "                best_person = people[0]  # fallback\n",
        "\n",
        "            # Step 4: normalize pose\n",
        "            pose_flat = best_person[\"pose_keypoints_2d\"]\n",
        "            pose = np.array(pose_flat).reshape(-1, 3)\n",
        "            pose_xy = pose[:, :2]\n",
        "\n",
        "            hip_center = (pose_xy[11] + pose_xy[12]) / 2\n",
        "            shoulder_span = np.linalg.norm(pose_xy[5] - pose_xy[6])\n",
        "            if shoulder_span == 0:\n",
        "                continue\n",
        "\n",
        "            pose_normalized = (pose_xy - hip_center) / shoulder_span\n",
        "\n",
        "            edges = [\n",
        "                (5, 7), (7, 9), (6, 8), (8, 10),\n",
        "                (11, 13), (13, 15), (12, 14), (14, 16),\n",
        "                (5, 6), (11, 12), (5, 11), (6, 12)\n",
        "            ]\n",
        "            rel_pose = [(pose_normalized[j] - pose_normalized[i]).tolist() for i, j in edges]\n",
        "\n",
        "            # Step 5: Save JSON\n",
        "            json_data = {\n",
        "                \"image\": filename,\n",
        "                \"pose_normalized\": pose_normalized.tolist(),\n",
        "                \"relative_pose_vectors\": rel_pose,\n",
        "                \"edges\": edges\n",
        "            }\n",
        "\n",
        "            json_name = filename.replace(\".jpg\", \".json\")\n",
        "            local_json_path = os.path.join(local_dir, json_name)\n",
        "\n",
        "            with open(local_json_path, \"w\") as f:\n",
        "                json.dump(json_data, f, indent=2)\n",
        "\n",
        "            # Upload to GCS\n",
        "            gcs_json_path = f\"{gcs_output_root}/{clip_id}/{json_name}\"\n",
        "            blob_out = bucket.blob(gcs_json_path)\n",
        "            blob_out.upload_from_filename(local_json_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in {filename}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGYPb2RfV4pO",
        "outputId": "2c69f106-c245-4b7a-acef-6e0081e8aab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DWPose: Using yolox_l.onnx for bbox detection and dw-ll_ucoco_384.onnx for pose estimation\n",
            "\n",
            "Processing clips_10s_video1/clip_001...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Bbox 1429.69ms\n",
            "DWPose: Pose 225.11ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1424.54ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   0%|          | 1/300 [00:03<18:50,  3.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 228.20ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2128.06ms\n",
            "DWPose: Pose 227.94ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1450.55ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   1%|          | 2/300 [00:08<21:27,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 237.06ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1515.60ms\n",
            "DWPose: Pose 230.74ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1428.46ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   1%|          | 3/300 [00:12<20:53,  4.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 230.71ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1449.13ms\n",
            "DWPose: Pose 234.72ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1525.48ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   1%|▏         | 4/300 [00:16<20:49,  4.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 336.08ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1879.81ms\n",
            "DWPose: Pose 236.78ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1508.57ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   2%|▏         | 5/300 [00:21<21:15,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 236.70ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1430.12ms\n",
            "DWPose: Pose 234.64ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1473.71ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   2%|▏         | 6/300 [00:25<20:43,  4.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 247.51ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1492.86ms\n",
            "DWPose: Pose 247.60ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1735.53ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   2%|▏         | 7/300 [00:29<21:03,  4.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 325.61ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1487.41ms\n",
            "DWPose: Pose 236.72ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1498.20ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   3%|▎         | 8/300 [00:33<20:43,  4.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 241.93ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1441.57ms\n",
            "DWPose: Pose 219.51ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1410.18ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   3%|▎         | 9/300 [00:37<20:11,  4.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 212.14ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1488.83ms\n",
            "DWPose: Pose 220.96ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1861.32ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   3%|▎         | 10/300 [00:42<20:46,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 317.48ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1479.51ms\n",
            "DWPose: Pose 246.30ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1496.12ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   4%|▎         | 11/300 [00:46<20:24,  4.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 221.15ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1429.18ms\n",
            "DWPose: Pose 234.31ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1451.52ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   4%|▍         | 12/300 [00:50<19:59,  4.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 228.64ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1409.40ms\n",
            "DWPose: Pose 223.93ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2060.00ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   4%|▍         | 13/300 [00:55<20:42,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 333.06ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1437.03ms\n",
            "DWPose: Pose 247.82ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1407.62ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   5%|▍         | 14/300 [00:59<20:15,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 226.36ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1434.71ms\n",
            "DWPose: Pose 249.63ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1444.71ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   5%|▌         | 15/300 [01:03<19:52,  4.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 225.13ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1525.01ms\n",
            "DWPose: Pose 344.46ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2138.13ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   5%|▌         | 16/300 [01:08<20:59,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 308.20ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1467.93ms\n",
            "DWPose: Pose 263.60ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1433.18ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   6%|▌         | 17/300 [01:12<20:21,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 231.38ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1501.73ms\n",
            "DWPose: Pose 240.79ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1432.69ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   6%|▌         | 18/300 [01:16<19:57,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 240.56ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1600.80ms\n",
            "DWPose: Pose 332.49ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2092.53ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   6%|▋         | 19/300 [01:21<20:53,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 229.95ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1465.67ms\n",
            "DWPose: Pose 250.89ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1483.28ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   7%|▋         | 20/300 [01:25<20:19,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 239.68ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1717.17ms\n",
            "DWPose: Pose 224.69ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1491.88ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   7%|▋         | 21/300 [01:30<20:15,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 270.12ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1920.11ms\n",
            "DWPose: Pose 342.09ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1795.47ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   7%|▋         | 22/300 [01:34<21:02,  4.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 229.34ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1982.75ms\n",
            "DWPose: Pose 235.85ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1427.24ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   8%|▊         | 23/300 [01:39<21:00,  4.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 244.75ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1414.30ms\n",
            "DWPose: Pose 221.00ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1415.01ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   8%|▊         | 24/300 [01:43<20:02,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 231.62ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2206.23ms\n",
            "DWPose: Pose 253.08ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1459.18ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   8%|▊         | 25/300 [01:48<20:38,  4.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 230.79ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1474.30ms\n",
            "DWPose: Pose 236.49ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1458.70ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   9%|▊         | 26/300 [01:52<20:06,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 229.54ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1418.24ms\n",
            "DWPose: Pose 219.48ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1419.21ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   9%|▉         | 27/300 [01:56<19:23,  4.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 226.04ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1963.38ms\n",
            "DWPose: Pose 250.64ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1438.18ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:   9%|▉         | 28/300 [02:00<19:42,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 230.98ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1401.55ms\n",
            "DWPose: Pose 223.19ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1429.29ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  10%|▉         | 29/300 [02:04<19:04,  4.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 224.06ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1388.22ms\n",
            "DWPose: Pose 226.85ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1542.48ms\n",
            "DWPose: Pose 330.96ms on 1 people\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  10%|█         | 30/300 [02:09<19:16,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Bbox 1760.74ms\n",
            "DWPose: Pose 244.89ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1417.86ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  10%|█         | 31/300 [02:13<18:56,  4.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 235.33ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1437.39ms\n",
            "DWPose: Pose 232.38ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1431.71ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  11%|█         | 32/300 [02:17<18:38,  4.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 235.92ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1417.95ms\n",
            "DWPose: Pose 232.02ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1697.02ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  11%|█         | 33/300 [02:21<18:48,  4.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 336.22ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1569.41ms\n",
            "DWPose: Pose 238.16ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1436.96ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  11%|█▏        | 34/300 [02:25<18:37,  4.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 219.14ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1430.93ms\n",
            "DWPose: Pose 217.92ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1402.06ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  12%|█▏        | 35/300 [02:29<18:12,  4.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 215.56ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1419.14ms\n",
            "DWPose: Pose 229.17ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1866.60ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  12%|█▏        | 36/300 [02:34<18:39,  4.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 326.32ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1484.86ms\n",
            "DWPose: Pose 241.20ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1420.88ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  12%|█▏        | 37/300 [02:38<18:23,  4.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 226.81ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1457.17ms\n",
            "DWPose: Pose 243.86ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1501.39ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  13%|█▎        | 38/300 [02:42<18:14,  4.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 236.63ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1461.94ms\n",
            "DWPose: Pose 242.80ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2107.90ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  13%|█▎        | 39/300 [02:47<19:04,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 363.10ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1482.87ms\n",
            "DWPose: Pose 248.87ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1493.04ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  13%|█▎        | 40/300 [02:51<18:21,  4.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 276.73ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1449.62ms\n",
            "DWPose: Pose 246.31ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1418.11ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  14%|█▎        | 41/300 [02:55<17:37,  4.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 223.35ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1429.88ms\n",
            "DWPose: Pose 232.69ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1885.52ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  14%|█▍        | 42/300 [02:59<17:46,  4.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 323.69ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1481.72ms\n",
            "DWPose: Pose 220.98ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1424.83ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  14%|█▍        | 43/300 [03:03<17:14,  4.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 222.65ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1473.54ms\n",
            "DWPose: Pose 229.29ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1463.49ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  15%|█▍        | 44/300 [03:06<16:54,  3.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 234.38ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1442.38ms\n",
            "DWPose: Pose 237.53ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1734.67ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  15%|█▌        | 45/300 [03:11<17:05,  4.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 337.52ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1720.56ms\n",
            "DWPose: Pose 229.77ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1420.13ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  15%|█▌        | 46/300 [03:15<17:04,  4.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 239.82ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1426.73ms\n",
            "DWPose: Pose 231.34ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1460.26ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  16%|█▌        | 47/300 [03:18<16:37,  3.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 222.18ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1442.94ms\n",
            "DWPose: Pose 231.13ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1407.05ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  16%|█▌        | 48/300 [03:22<16:25,  3.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 316.78ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2010.61ms\n",
            "DWPose: Pose 220.27ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1404.96ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  16%|█▋        | 49/300 [03:27<16:51,  4.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 231.05ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1391.73ms\n",
            "DWPose: Pose 235.54ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1364.23ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  17%|█▋        | 50/300 [03:30<16:17,  3.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 222.46ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1417.82ms\n",
            "DWPose: Pose 225.52ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1469.93ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  17%|█▋        | 51/300 [03:34<16:02,  3.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 240.82ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2288.23ms\n",
            "DWPose: Pose 352.96ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1606.35ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  17%|█▋        | 52/300 [03:39<17:15,  4.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 227.82ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1532.22ms\n",
            "DWPose: Pose 280.18ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1528.46ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  18%|█▊        | 53/300 [03:43<16:57,  4.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 227.40ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1441.55ms\n",
            "DWPose: Pose 220.43ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1607.04ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  18%|█▊        | 54/300 [03:47<16:40,  4.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 240.70ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2507.46ms\n",
            "DWPose: Pose 378.27ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1735.33ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  18%|█▊        | 55/300 [03:52<18:06,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 231.12ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1465.30ms\n",
            "DWPose: Pose 245.41ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1485.07ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  19%|█▊        | 56/300 [03:56<17:21,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 236.12ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1590.96ms\n",
            "DWPose: Pose 241.35ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1658.51ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  19%|█▉        | 57/300 [04:00<17:11,  4.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 252.68ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2331.24ms\n",
            "DWPose: Pose 410.50ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1682.22ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  19%|█▉        | 58/300 [04:05<18:11,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 259.40ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1506.49ms\n",
            "DWPose: Pose 254.62ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1528.20ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  20%|█▉        | 59/300 [04:09<17:26,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 247.71ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1622.60ms\n",
            "DWPose: Pose 262.21ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1558.15ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  20%|██        | 60/300 [04:13<17:06,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 255.95ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2330.91ms\n",
            "DWPose: Pose 368.83ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1742.10ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  20%|██        | 61/300 [04:18<18:03,  4.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 248.43ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1578.54ms\n",
            "DWPose: Pose 251.72ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1575.74ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  21%|██        | 62/300 [04:23<17:27,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 256.18ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1659.82ms\n",
            "DWPose: Pose 247.44ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1669.05ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  21%|██        | 63/300 [04:27<17:13,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 250.96ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2346.86ms\n",
            "DWPose: Pose 251.13ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1589.18ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  21%|██▏       | 64/300 [04:32<17:46,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 274.95ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1714.08ms\n",
            "DWPose: Pose 281.37ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1748.89ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  22%|██▏       | 65/300 [04:36<17:38,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 273.08ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1749.09ms\n",
            "DWPose: Pose 278.13ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2179.88ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  22%|██▏       | 66/300 [04:41<18:09,  4.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 384.12ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1927.61ms\n",
            "DWPose: Pose 259.56ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1641.77ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  22%|██▏       | 67/300 [04:46<17:58,  4.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 269.75ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1529.09ms\n",
            "DWPose: Pose 226.55ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1636.58ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  23%|██▎       | 68/300 [04:50<17:16,  4.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 262.87ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1686.37ms\n",
            "DWPose: Pose 251.91ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2220.53ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  23%|██▎       | 69/300 [04:55<17:48,  4.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 353.07ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1536.77ms\n",
            "DWPose: Pose 264.15ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1507.26ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  23%|██▎       | 70/300 [04:59<16:59,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 236.91ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1566.08ms\n",
            "DWPose: Pose 229.17ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1492.13ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  24%|██▎       | 71/300 [05:03<16:23,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 240.01ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1466.66ms\n",
            "DWPose: Pose 241.57ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2074.73ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  24%|██▍       | 72/300 [05:07<16:36,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 347.07ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1463.16ms\n",
            "DWPose: Pose 230.47ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1451.02ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  24%|██▍       | 73/300 [05:11<15:54,  4.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 230.62ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1430.16ms\n",
            "DWPose: Pose 224.06ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1477.46ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  25%|██▍       | 74/300 [05:15<15:21,  4.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 237.82ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1487.94ms\n",
            "DWPose: Pose 231.30ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1927.17ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  25%|██▌       | 75/300 [05:19<15:40,  4.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 320.37ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1530.38ms\n",
            "DWPose: Pose 231.74ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1428.70ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  25%|██▌       | 76/300 [05:23<15:14,  4.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 252.01ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1458.63ms\n",
            "DWPose: Pose 256.66ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1582.64ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  26%|██▌       | 77/300 [05:27<15:03,  4.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 258.75ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1591.38ms\n",
            "DWPose: Pose 268.43ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2039.41ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  26%|██▌       | 78/300 [05:32<15:42,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 350.50ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1699.31ms\n",
            "DWPose: Pose 249.72ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1602.20ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  26%|██▋       | 79/300 [05:36<15:38,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 261.85ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1600.44ms\n",
            "DWPose: Pose 265.18ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1617.90ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  27%|██▋       | 80/300 [05:40<15:28,  4.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 252.97ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1603.46ms\n",
            "DWPose: Pose 248.98ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2275.87ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  27%|██▋       | 81/300 [05:45<16:11,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 364.74ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1586.32ms\n",
            "DWPose: Pose 256.12ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1584.48ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  27%|██▋       | 82/300 [05:49<15:42,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 255.06ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1588.57ms\n",
            "DWPose: Pose 266.60ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1618.02ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  28%|██▊       | 83/300 [05:53<15:23,  4.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 248.37ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1570.62ms\n",
            "DWPose: Pose 285.20ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2352.27ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  28%|██▊       | 84/300 [05:58<16:04,  4.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 367.64ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1585.30ms\n",
            "DWPose: Pose 252.90ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1593.49ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  28%|██▊       | 85/300 [06:03<15:42,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 247.57ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1640.22ms\n",
            "DWPose: Pose 251.98ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1612.53ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  29%|██▊       | 86/300 [06:07<15:24,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 253.93ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1804.12ms\n",
            "DWPose: Pose 363.44ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2311.86ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  29%|██▉       | 87/300 [06:12<16:15,  4.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 260.41ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1576.68ms\n",
            "DWPose: Pose 246.53ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1646.81ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  29%|██▉       | 88/300 [06:16<15:43,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 256.75ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1601.63ms\n",
            "DWPose: Pose 250.89ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1602.26ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  30%|██▉       | 89/300 [06:20<15:18,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 247.76ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1882.27ms\n",
            "DWPose: Pose 353.34ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2165.91ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  30%|███       | 90/300 [06:25<15:59,  4.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 254.42ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1616.94ms\n",
            "DWPose: Pose 265.31ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1614.81ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  30%|███       | 91/300 [06:29<15:32,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 267.57ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1601.89ms\n",
            "DWPose: Pose 268.44ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1556.20ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  31%|███       | 92/300 [06:34<15:04,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 255.07ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2050.44ms\n",
            "DWPose: Pose 357.15ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2040.51ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  31%|███       | 93/300 [06:39<15:48,  4.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 261.26ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1593.40ms\n",
            "DWPose: Pose 247.42ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1555.36ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  31%|███▏      | 94/300 [06:43<15:14,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 246.12ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1571.78ms\n",
            "DWPose: Pose 249.51ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1570.92ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  32%|███▏      | 95/300 [06:47<14:45,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 246.45ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2094.24ms\n",
            "DWPose: Pose 370.89ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1840.15ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  32%|███▏      | 96/300 [06:52<15:23,  4.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 243.51ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1576.93ms\n",
            "DWPose: Pose 245.51ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1566.23ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  32%|███▏      | 97/300 [06:56<14:51,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 257.76ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1538.56ms\n",
            "DWPose: Pose 245.24ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1548.00ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  33%|███▎      | 98/300 [07:00<14:26,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 270.16ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2166.89ms\n",
            "DWPose: Pose 382.48ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1793.63ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  33%|███▎      | 99/300 [07:05<15:07,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 256.24ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1597.52ms\n",
            "DWPose: Pose 244.27ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1570.90ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  33%|███▎      | 100/300 [07:09<14:36,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 242.15ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1596.75ms\n",
            "DWPose: Pose 246.82ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1578.83ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  34%|███▎      | 101/300 [07:13<14:16,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 243.20ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2369.87ms\n",
            "DWPose: Pose 371.34ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1752.28ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  34%|███▍      | 102/300 [07:18<15:03,  4.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 251.81ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1588.53ms\n",
            "DWPose: Pose 253.90ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1648.59ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  34%|███▍      | 103/300 [07:23<14:36,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 266.48ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1642.85ms\n",
            "DWPose: Pose 252.77ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1602.21ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  35%|███▍      | 104/300 [07:27<14:15,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 245.50ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2237.23ms\n",
            "DWPose: Pose 259.78ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1600.93ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  35%|███▌      | 105/300 [07:31<14:34,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 262.37ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1422.83ms\n",
            "DWPose: Pose 249.70ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1532.28ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  35%|███▌      | 106/300 [07:35<13:53,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 236.45ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1556.08ms\n",
            "DWPose: Pose 237.82ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1471.56ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  36%|███▌      | 107/300 [07:39<13:29,  4.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 265.22ms on 1 people\n",
            "\n",
            "DWPose: Bbox 2121.65ms\n",
            "DWPose: Pose 253.76ms on 1 people\n",
            "\n",
            "DWPose: Bbox 1506.95ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🎯 clip_001:  36%|███▌      | 108/300 [07:44<13:43,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DWPose: Pose 231.81ms on 1 people\n",
            "\n"
          ]
        }
      ]
    }
  ]
}